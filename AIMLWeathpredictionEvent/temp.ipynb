{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.37515034],\n",
       "       [0.33306613],\n",
       "       [0.31022045],\n",
       "       ...,\n",
       "       [0.3470942 ],\n",
       "       [0.34228462],\n",
       "       [0.4       ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('./processedData.csv')\n",
    "\n",
    "# Parse the 'Full date' column and set it as index\n",
    "df['Full date'] = pd.to_datetime(df['Full date'])\n",
    "df.set_index('Full date', inplace=True)\n",
    "\n",
    "# Feature Engineering: Extract features from the date\n",
    "df['DayOfYear'] = df.index.dayofyear\n",
    "df['Month'] = df.index.month\n",
    "df['Day'] = df.index.day\n",
    "df['Year'] = df.index.year\n",
    "\n",
    "# Normalize the target variable (Temp Max)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df['Temp Max'] = scaler.fit_transform(df['Temp Max'].values.reshape(-1, 1))\n",
    "data = df[['Temp Max']].values\n",
    "data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data) * 0.8)\n",
    "train, test = data[:train_size], data[train_size:]\n",
    "\n",
    "# Function to create a dataset suitable for LSTM\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    X, y = [], []\n",
    "    for i in range(len(dataset) - time_step - 1):\n",
    "        X.append(dataset[i:(i + time_step), 0])\n",
    "        y.append(dataset[i + time_step, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Create dataset with a reasonable time_step\n",
    "time_step = 30  # Adjust as needed\n",
    "X_train, y_train = create_dataset(train, time_step)\n",
    "X_test, y_test = create_dataset(test, time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.37515034, 0.33306613, 0.31022045, 0.32424852, 0.35030061,\n",
       "        0.35871748, 0.31462929, 0.33787578, 0.37755513, 0.38156316,\n",
       "        0.3915832 , 0.38597193, 0.42164332, 0.40320641, 0.39478961,\n",
       "        0.37675351, 0.40601201, 0.41322645, 0.438477  , 0.43687375,\n",
       "        0.43206418, 0.43246499, 0.40961923, 0.42124251, 0.43086174,\n",
       "        0.43607213, 0.43166336, 0.45410823, 0.44368738, 0.41122247]),\n",
       " 0.4280561442077757)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0],y_train[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_knime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
